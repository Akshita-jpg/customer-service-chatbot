{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZsmdM0NY92Y"
      },
      "source": [
        "#Task 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwaIzzF4WsDT"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "0AwadhucJ5WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMBxHl5afnho"
      },
      "source": [
        "#Task 2: Load Lightweight model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"Model Loaded Successfully âœ…\")"
      ],
      "metadata": {
        "id": "eprmcFlHKWb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3: Initialise FAQ knowledge Base"
      ],
      "metadata": {
        "id": "tAUG15xnPq8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faq_dict = {\n",
        "    \"return policy\": \"Our return policy allows returns within 30 days with a valid receipt.\",\n",
        "    \"refund\": \"Refunds are processed within 5-7 business days after approval.\",\n",
        "    \"shipping\": \"Standard shipping takes 3-5 business days.\",\n",
        "    \"cancel order\": \"To cancel your order, please provide your order ID.\",\n",
        "    \"contact\": \"You can contact our support team at support@company.com.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "_W5KM-XiKeNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4: FAQ Detection Function\n"
      ],
      "metadata": {
        "id": "EUTCgYGYKtEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_faq(user_input):\n",
        "    user_input = user_input.lower()\n",
        "    for key in faq_dict:\n",
        "        if key in user_input:\n",
        "            return faq_dict[key]\n",
        "    return None"
      ],
      "metadata": {
        "id": "Na7RbI0lKqKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conversation memory\n",
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a professional and polite customer service assistant. Always reply clearly and briefly.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "sq9c-UpaG_Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5: AI Response Generator(With Memory)"
      ],
      "metadata": {
        "id": "45Oq8_i7QL4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDBUWcq-fqPh"
      },
      "outputs": [],
      "source": [
        "def generate_ai_response(user_input):\n",
        "\n",
        "    global conversation\n",
        "\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Apply chat template\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        conversation,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=80,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    reply = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    reply = reply.split(\"assistant\")[-1].strip()\n",
        "\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 6: Initialise Chatbot Conversation"
      ],
      "metadata": {
        "id": "lsclIVfELQ42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"======================================\")\n",
        "print(\"ðŸ¤– Welcome to Smart Customer Service Chatbot\")\n",
        "print(\"Type 'exit' to end conversation\")\n",
        "print(\"======================================\\n\")"
      ],
      "metadata": {
        "id": "TYdSNHuwLeEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUu9y6EzZSKl"
      },
      "source": [
        "#Task 7: Testing section\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9wn1GojXHIt"
      },
      "outputs": [],
      "source": [
        "test_questions = [\n",
        "    \"What is your return policy?\",\n",
        "    \"I want a refund\",\n",
        "    \"My order is delayed\"\n",
        "]\n",
        "\n",
        "print(\"Running Test Cases...\\n\")\n",
        "\n",
        "for question in test_questions:\n",
        "    print(\"You:\", question)\n",
        "\n",
        "    faq_response = check_faq(question)\n",
        "\n",
        "    if faq_response:\n",
        "        print(\"Chatbot (FAQ):\", faq_response)\n",
        "    else:\n",
        "        print(\"Chatbot (AI):\", generate_ai_response(question))\n",
        "\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interactive Chat"
      ],
      "metadata": {
        "id": "7Bo1JR_YFiqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Thank you for contacting us. Have a great day! ðŸ˜Š\")\n",
        "        break\n",
        "\n",
        "    faq_response = check_faq(user_input)\n",
        "\n",
        "    if faq_response:\n",
        "        print(\"Chatbot (FAQ):\", faq_response)\n",
        "    else:\n",
        "        reply = generate_ai_response(user_input)\n",
        "        print(\"Chatbot (AI):\", reply)"
      ],
      "metadata": {
        "id": "ErIaWlbBFc_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}